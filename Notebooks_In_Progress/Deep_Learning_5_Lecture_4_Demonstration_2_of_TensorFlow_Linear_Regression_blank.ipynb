{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124ef9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install d2l==1.0.0-beta0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54939284",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# <b> Concise Implementation of Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99eedc",
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f6f7832",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## Defining the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328dca04",
   "metadata": {
    "origin_pos": 9,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "In Keras, the fully connected layer is defined in the `Dense` class.\n",
    "Since we only want to generate a single scalar output,\n",
    "we set that number to 1.\n",
    "It is worth noting that, for convenience,\n",
    "Keras does not require us to specify\n",
    "the input shape for each layer.\n",
    "We don't need to tell Keras\n",
    "how many inputs go into this linear layer.\n",
    "When we first try to pass data through our model,\n",
    "e.g., when we execute `net(X)` later,\n",
    "Keras will automatically infer\n",
    "the number of inputs to each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f1d60",
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad78fef",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "In the `forward` method, we just invoke the built-in `__call__` function of the predefined layers to compute the outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729744e",
   "metadata": {
    "origin_pos": 13,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b74c435f",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "## <b> Defining the Loss Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c9a26",
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "The `MeanSquaredError` class returns the average loss over examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a39e4",
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d897aab2",
   "metadata": {
    "origin_pos": 21,
    "tags": []
   },
   "source": [
    "## <b> Defining the Optimization Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039d53a",
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "Minibatch SGD is a standard tool\n",
    "for optimizing neural networks\n",
    "and thus Keras supports it alongside a number of\n",
    "variations on this algorithm in the `optimizers` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c339f",
   "metadata": {
    "origin_pos": 25,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9391826",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "## Training\n",
    "\n",
    "We will use `Trainer` class to train & `fit` to fit the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88e02a",
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5008be0",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "Below, we\n",
    "[**compare the model parameters learned\n",
    "by training on finite data\n",
    "and the actual parameters**]\n",
    "that generated our dataset.\n",
    "To access parameters,\n",
    "we access the weights and bias\n",
    "of the layer that we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b1d73",
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "tensorflow"
    ],
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad8971b",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db967c9",
   "metadata": {
    "origin_pos": 35,
    "tab": [
     "tensorflow"
    ]
   },
   "source": [
    "In TensorFlow, the `data` module provides tools for data processing,\n",
    "the `keras` module defines a large number of neural network layers and common loss functions.\n",
    "Moreover, the `initializers` module provides various methods for model parameter initialization.\n",
    "Dimensionality and storage for networks are automatically inferred\n",
    "(but be careful not to attempt to access parameters before they have been initialized).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
